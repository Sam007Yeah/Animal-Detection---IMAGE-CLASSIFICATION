# -*- coding: utf-8 -*-
"""FINAL_PROJECT.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1r3ODflnh0Ns9AFM7HOitQIAdrh_Yfefv

RUN-2 with a different dataset
"""

#importing all the dependencies
import warnings
from sklearn.exceptions import ConvergenceWarning
warnings.filterwarnings('ignore', category = ConvergenceWarning)
warnings.simplefilter(action = 'ignore', category = FutureWarning)
warnings.simplefilter(action = 'ignore', category = UserWarning)

import itertools
import numpy as np
import pandas as pd
import os
import matplotlib.pyplot as plt
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split
from PIL import Image
from sklearn.metrics import classification_report, f1_score, confusion_matrix

#tensorflow libraries
import tensorflow as tf
from tensorflow import keras
from keras.layers import Dense, Dropout, BatchNormalization
from tensorflow.keras.optimizers import Adam
from tensorflow.keras import layers, models, Model
from keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.callbacks import Callback, EarlyStopping, ModelCheckpoint, ReduceLROnPlateau
from tensorflow.keras import mixed_precision
mixed_precision.set_global_policy('mixed_float16')

print(tf.__version__)

#MOUNTING THE DRIVE FOR EXTRACTING DATA

from google.colab import drive
drive.mount('/content/drive')

#SETTING THE PATH FOR THE LOCATION OF THE DATA SET

path = 'drive/MyDrive/DATA/ANIMALS/raw-img'

#SETTING UP THE DICTIONARY CONSISTING OF THE IMAGES AND THEIR RESPECTIVE LABELS
data = {'imgpath': [], 'labels': []}

#BUILDING THE FILE NAMES AND THEIR RESPECTIVE CLASSES or LABELS
category = os.listdir(path)
for folder in category:

  folderpath = os.path.join(path, folder)
  filelist = os.listdir(folderpath)
  for file in filelist:
    fpath = os.path.join(folderpath, file)
    data['imgpath'].append(fpath)
    data['labels'].append(folder)

#BUILDING A PANDA DATA FRAME FROM DATA
df = pd.DataFrame(data)

#convert labels to numbers
lb = LabelEncoder()
df['encoded_labels'] = lb.fit_transform(df['labels'])

#DISPLAYING RANDOM FILES WITH THEIR RESPECTIVE LABELS AND ENCODED LABELS
df.sample(n = 15, random_state = 1)

#SHAPE OF THE DATASET
print("Shape of the dataset: ", df.shape)
print("_______________________________________")
print("Number of null values: ")
print(df.isnull().sum())
print("_______________________________________")
print("Number of unique values: ")
print(df.nunique())

print("---------------------------------------")
print("Number of images per category : ")
print(df.labels.value_counts())

#split data into traning and test data
'''
TOTAL ITEMS : 26187 images
SPLITTING THE DATA AS FOLLOWS:
  1. TRAINING DATA : 80% of the DATASET ( 20949 images )
  2. VALIDATION DATA : 12 % of the REMANING DATASET( 3142 images )
  3. TESTING DATA : REAMAING 8 % ( 2096 images )
'''

train_df, Temp_df = train_test_split(df, train_size = 0.80, shuffle = True, random_state = 124)
valid_df, test_df = train_test_split(Temp_df, train_size = 0.60, shuffle = True, random_state = 124)
train_df = train_df.reset_index(drop = True)
valid_df = valid_df.reset_index(drop = True)
test_df = test_df.reset_index(drop = True)

print("----------Train-------------")
print(train_df[["imgpath", "labels"]].head(5))
print(train_df.shape)
print("--------Validation----------")
print(valid_df[["imgpath", "labels"]].head(5))
print(valid_df.shape)
print("----------Test--------------")
print(test_df[["imgpath", "labels"]].head(5))
print(test_df.shape)

#SHOWING SAMPLE DATA USING MATPLOTLIB LIBRARY IN Python
plt.figure(figsize = (15, 12))
for i, row in test_df.sample(n = 16).reset_index().iterrows():
  plt.subplot(4, 4, i + 1)
  image_path = row['imgpath']
  image = Image.open(image_path)
  plt.imshow(image)
  plt.title(row['labels'])
  plt.axis('off')

plt.show()

#Creating DataLoaders

BATCH_SIZE = 32
IMAGE_SIZE = (224, 224)


#USING IMAGE DATA GENERATOR FROM TENSORFLOW TI BUILD THE DATA GENERATORS FOR SETTING UP THE DATA
generator = ImageDataGenerator(
    preprocessing_function = tf.keras.applications.efficientnet.preprocess_input
)



train_images = generator.flow_from_dataframe(
    dataframe = train_df,
    x_col = 'imgpath',
    y_col = 'labels',
    target_size = IMAGE_SIZE,
    color_mode = 'rgb',
    class_mode = 'categorical',
    batch_size = BATCH_SIZE,
    shuffle = True,
    seed = 42
)

val_images = generator.flow_from_dataframe(
    dataframe=valid_df,
    x_col='imgpath',
    y_col='labels',
    target_size=IMAGE_SIZE,
    color_mode='rgb',
    class_mode='categorical',
    batch_size=BATCH_SIZE,
    shuffle=False
)

test_images = generator.flow_from_dataframe(
    dataframe=test_df,
    x_col='imgpath',
    y_col='labels',
    target_size=IMAGE_SIZE,
    color_mode='rgb',
    class_mode='categorical',
    batch_size=BATCH_SIZE,
    shuffle=False
)

#MODEL STRUCTURE USING THE PRE-TRAINED MODEL OF EFFICENTNETB2 EXCLUDING THE TOP LAYER

pretrained_model = tf.keras.applications.EfficientNetB2(
    input_shape = (224, 224, 3),
    include_top = False,
    weights = 'imagenet',
    pooling = 'max'
)

#SETTING THE DEFAULT VALUE OF THE MODEL TO FALSE TO START TRAINING
for i, layer in enumerate(pretrained_model.layers):
  pretrained_model.layers[i].trainable = False

#TOTAL NUMBER OF CLASSES IN TOTAL
num_classes = len(set(train_images.classes))

'''
MODEL STRUCTURE :

'''


#data augmentation
augment = tf.keras.Sequential([
    layers.experimental.preprocessing.RandomFlip("horizontal"),
    layers.experimental.preprocessing.RandomRotation(0.2),
    layers.experimental.preprocessing.RandomZoom(0.2),
    layers.experimental.preprocessing.RandomContrast(0.2),
], name = 'AugmentationLayer')


inputs = layers.Input(shape = (224, 224, 3), name = 'inputLayer')
x = augment(inputs)
pretrained_out = pretrained_model(x, training  = False)
x = layers.Dense(256)(pretrained_out)
x = layers.Activation(activation = 'relu')(x)
x = BatchNormalization()(x)
x = layers.Dropout(0, 4)(x)
x = layers.Dense(num_classes)(x)
outputs = layers.Activation(activation = 'softmax', dtype = tf.float32, name = 'activationLayer')(x)
model = Model(inputs = inputs, outputs = outputs)

model.compile(
    optimizer = Adam(0.00001),
    loss = 'categorical_crossentropy',
    metrics = ['accuracy']
)

print(model.summary())

#training :Transfer Learning

history = model.fit(
    train_images,
    steps_per_epoch = len(train_images),
    validation_data = val_images,
    validation_steps = len(val_images),
    epochs = 10,
    callbacks = [
        EarlyStopping(monitor = 'val_loss',
                      patience = 5,
                      restore_best_weights = True),
        ReduceLROnPlateau(monitor = 'val_loss', factor = 0.2, patience = 2, mode = 'min')
    ]
)
# model.save_weights('drive/MyDrive/PROJECT/MODELS/animals.h5')
# model.save('drive/MyDrive/PROJECT/MODELS/animals.h5')

tr_acc = history.history['accuracy']
tr_loss = history.history['loss']
val_acc = history.history['val_accuracy']
val_loss = history.history['val_loss']

index_loss = np.argmin(val_loss)
val_lowest = val_loss[index_loss]

index_acc = np.argmax(val_acc)
acc_highest = val_acc[index_acc]

Epochs = [i + 1 for i in range(len(tr_acc))]
loss_label = f'best epoch = {str(index_loss + 1)}'
acc_label = f'best epoch = {str(index_acc + 1)}'

plt.figure(figsize = (20, 8))
plt.style.use('fivethirtyeight')

plt.subplot(1, 2, 1)
plt.plot(Epochs, tr_loss, 'r', label = 'Training Loss')
plt.plot(Epochs, val_loss, 'g', label = 'Validation Loss')
plt.scatter(index_loss + 1, val_lowest, s = 150, c = 'blue', label = loss_label)
plt.title('Training and Validation Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()

plt.subplot(1, 2, 2)
plt.plot(Epochs, tr_acc, 'r', label= 'Training Accuracy')
plt.plot(Epochs, val_acc, 'g', label= 'Validation Accuracy')
plt.scatter(index_acc + 1 , acc_highest, s= 150, c= 'blue', label= acc_label)
plt.title('Training and Validation Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()

plt.tight_layout
plt.show()

model.save('drive/MyDrive/PROJECT/MODELS/animals.h5')
model.save('drive/MyDrive/PROJECT/MODELS/animals')

results = model.evaluate(test_images, verbose=0)

print("    Test Loss: {:.5f}".format(results[0]))
print("Test Accuracy: {:.2f}%".format(results[1] * 100))

y_true = test_images.classes
y_pred = np.argmax(model.predict(test_images), axis = 1)
f1 = f1_score(y_true, y_pred, average='macro')
print("F1 Score:", f1)
print(classification_report(y_true, y_pred, target_names=test_images.class_indices.keys()))

classes = dict(zip(test_images.class_indices.values(), test_images.class_indices.keys()))
Predictions = pd.DataFrame({"Image Index" : list(range(len(test_images.labels))),
                            "Test Labels" : test_images.labels,
                            "Test Classes" : [classes[i] for i in test_images.labels],
                            "Prediction Labels" : y_pred,
                            "Prediction Classes" : [classes[i] for i in y_pred],
                            "Path": test_images.filenames,
                            "Prediction Probability" : [x for x in np.asarray(tf.reduce_max(model.predict(test_images), axis = 1))]
                           })
Predictions.head(8)

plt.figure(figsize=(20,20))
for i, row in Predictions[Predictions["Test Labels"] != Predictions["Prediction Labels"]].sort_values("Prediction Probability").tail(20).reset_index().iterrows():
    plt.subplot(5,4,i+1)
    image_path = row['Path']
    image = Image.open(image_path)
    plt.imshow(image)
    plt.title(f'TRUE: {row["Test Classes"]} | PRED: {row["Prediction Classes"]}', fontsize=8)
    plt.axis('off')

plt.show()

preds = model.predict_generator(test_images)
y_pred = np.argmax(preds, axis=1)
g_dict = test_images.class_indices
classes = list(g_dict.keys())

# Confusion matrix
cm = confusion_matrix(test_images.classes, y_pred)

plt.figure(figsize= (10, 10))
plt.imshow(cm, interpolation= 'nearest', cmap= plt.cm.Blues)
plt.title('Confusion Matrix')
plt.colorbar()

tick_marks = np.arange(len(classes))
plt.xticks(tick_marks, classes, rotation= 45)
plt.yticks(tick_marks, classes)


thresh = cm.max() / 2.
for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):
    plt.text(j, i, cm[i, j], horizontalalignment= 'center', color= 'white' if cm[i, j] > thresh else 'black')

plt.tight_layout()
plt.ylabel('True Label')
plt.xlabel('Predicted Label')

plt.show()

def predict_single_image(image_path, model):
    # Load and preprocess the image
    img = tf.keras.preprocessing.image.load_img(image_path, target_size=(224, 224))
    img_array = tf.keras.preprocessing.image.img_to_array(img)
    img_array = tf.expand_dims(img_array, 0)  # Create a batch

    # Make predictions
    predictions = model.predict(img_array)

    # Assuming `test_images.class_indices` is available
    classes = {v: k for k, v in test_images.class_indices.items()}

    # Get the predicted class label
    predicted_label = classes[np.argmax(predictions)]

    # Get the predicted probability
    predicted_probability = np.max(predictions)

    return predicted_label, predicted_probability

# Example usage
image_path = "drive/MyDrive/DATA/animals/inf/dog.jpg"  # Change this to the path of your image
predicted_label, predicted_probability = predict_single_image(image_path, model)
print("Predicted Label:", predicted_label)
print("Predicted Probability:", predicted_probability)

model = tf.keras.models.load_model('drive/MyDrive/PROJECT/MODELS/animals.h5')

model.summary()

#FINAL CODE FOR EXPORT
def predict_single_image(image_path, model):
    # Load and preprocess the image
    img = tf.keras.preprocessing.image.load_img(image_path, target_size=(224, 224))
    img_array = tf.keras.preprocessing.image.img_to_array(img)
    img_array = tf.expand_dims(img_array, 0)  # Create a batch

    # Make predictions
    predictions = model.predict(img_array)

    # Assuming `test_images.class_indices` is available
    #classes = {v: k for k, v in test_images.class_indices.items()}
    classes = {v: k for k, v in tc.items()}

    # Get the predicted class label
    predicted_label = classes[np.argmax(predictions)]

    # Get the predicted probability
    predicted_probability = np.max(predictions)

    return predicted_label, predicted_probability

# Example usage

tc = {
    'cane' : 0,
    'cavallo' : 1,
    'elefante' : 2,
    'farfalla' : 3,
    'gallina' : 4,
    'gatto' : 5,
    'mucca' : 6,
    'pecora' : 7,
    'ragno' : 8,
    'scoiattolo' : 9

}

image_path = "drive/MyDrive/PROJECT/TEST/scoiattolo.jpeg"  # Change this to the path of your image
predicted_label, predicted_probability = predict_single_image(image_path, model)
print("Predicted Label:", predicted_label)
print("Predicted Probability:", predicted_probability)

plt.plot(5,4)
image = Image.open(image_path)
plt.imshow(image)
plt.show()



